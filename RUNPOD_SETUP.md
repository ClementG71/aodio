# Guide complet : Configuration de l'endpoint RunPod pour Pyannote

Ce guide vous explique √©tape par √©tape comment cr√©er et configurer un endpoint RunPod pour la diarisation avec Pyannote 4.0.1.

## üìã Pr√©requis

1. **Compte RunPod** : Cr√©ez un compte sur [https://www.runpod.io](https://www.runpod.io)
2. **Compte Hugging Face** : Cr√©ez un compte sur [https://huggingface.co](https://huggingface.co)
3. **Cr√©dits RunPod** : Ajoutez des cr√©dits √† votre compte RunPod (minimum $10 recommand√©)

## üîë √âtape 1 : Configuration Hugging Face

### 1.1 Accepter les conditions d'utilisation Pyannote

1. Allez sur [https://huggingface.co/pyannote/speaker-diarization-3.1](https://huggingface.co/pyannote/speaker-diarization-3.1)
2. Cliquez sur "Agree and access repository"
3. Acceptez les conditions d'utilisation

### 1.2 Cr√©er un token d'acc√®s

1. Allez sur [https://huggingface.co/settings/tokens](https://huggingface.co/settings/tokens)
2. Cliquez sur "New token"
3. Donnez un nom (ex: "runpod-pyannote")
4. S√©lectionnez le type "Read"
5. Copiez le token g√©n√©r√© (vous en aurez besoin plus tard)

## üöÄ √âtape 2 : Cr√©er l'endpoint RunPod

### 2.1 Acc√©der √† RunPod

1. Connectez-vous sur [https://www.runpod.io/console](https://www.runpod.io/console)
2. Allez dans l'onglet "Serverless" (menu de gauche)

### 2.2 Cr√©er un nouvel endpoint

1. Cliquez sur "New Endpoint"
2. Vous avez le choix entre 3 options :
   - **Git** : Si vous avez d√©j√† un repository GitHub avec le code
   - **Docker** : Si vous voulez utiliser une image Docker existante
   - **Template** : Templates pr√©-configur√©s (non utilis√© ici)

#### Option recommand√©e : Git (si vous avez un repo GitHub)

Si vous avez d√©j√† cr√©√© un repository GitHub avec le dossier `runpod_worker/` :

1. **S√©lectionnez "Git"**
2. Remplissez :
   - **Nom** : `aodio` (ou `pyannote-diarization`)
   - **GPU Type** : RTX 3090 ou A100 (minimum 16 GB VRAM)
   - **Repository URL** : URL de votre repo GitHub (ex: `https://github.com/ClementG71/aodio`)
   - **Branch** : `main` (ou votre branche)
   - **Dockerfile Path** : `runpod_worker/Dockerfile.runpod` (le Dockerfile pour RunPod est dans le dossier runpod_worker/)
   - **Handler Path** : **LAISSER VIDE** (le Dockerfile g√®re le chemin via CMD)
   - **Container Disk** : 20 GB
   
   **Note importante** : 
   - Si vous obtenez une erreur `path "/app/.../temp/app/handler.py" not found`, **laissez le Handler Path vide**
   - Le Dockerfile copie `runpod_worker/handler.py` vers `/app/handler.py` dans l'image Docker
   - Le CMD du Dockerfile (`CMD ["python", "handler.py"]`) ex√©cute le handler
   - RunPod utilisera automatiquement le CMD du Dockerfile si le Handler Path est vide

#### Option alternative : Docker (code inline)

Si vous pr√©f√©rez coller le code directement dans RunPod :

1. **S√©lectionnez "Docker"**
2. Remplissez :
   - **Nom** : `pyannote-diarization`
   - **GPU Type** : RTX 3090 ou A100 (minimum 16 GB VRAM)
   - **Docker Image** : `runpod/pytorch:2.1.0-py3.10-cuda11.8.0-devel`
   - **Container Disk** : 20 GB
   - **Handler Path** : `/app/handler.py` (sera configur√© apr√®s)

### 2.3 Configurer les variables d'environnement

Dans la section "Environment Variables", ajoutez :

```
HF_TOKEN=votre-token-huggingface-ici
```

Remplacez `votre-token-huggingface-ici` par le token cr√©√© √† l'√©tape 1.2.

### 2.4 Note importante

Pour le d√©ploiement du code, vous avez deux options :
- **Option A (Recommand√©e)** : Utiliser un repository Git (voir √©tape 4)
- **Option B** : Utiliser le code inline dans l'interface RunPod

Nous recommandons l'Option A car elle est plus maintenable.

## üíª √âtape 3 : Code du worker

### 3.1 Cr√©er le fichier worker

Cr√©ez un fichier `handler.py` avec le code suivant :

```python
"""
Worker RunPod pour la diarisation avec Pyannote 4.0.1
"""
import os
import tempfile
import requests
import runpod
from pyannote.audio import Pipeline
import torch

# Configuration
DIARIZATION_MODEL = "pyannote/speaker-diarization-3.1"
HF_TOKEN = os.getenv("HF_TOKEN")

# Initialisation du pipeline (charg√© une seule fois au d√©marrage)
print("Chargement du mod√®le Pyannote...")
pipeline = Pipeline.from_pretrained(
    DIARIZATION_MODEL,
    use_auth_token=HF_TOKEN
)
pipeline.to(torch.device("cuda" if torch.cuda.is_available() else "cpu"))
print("Mod√®le Pyannote charg√© avec succ√®s!")


def download_audio(audio_url: str) -> str:
    """
    T√©l√©charge un fichier audio depuis une URL
    
    Args:
        audio_url: URL du fichier audio
        
    Returns:
        str: Chemin local du fichier t√©l√©charg√©
    """
    # Cr√©er un fichier temporaire
    temp_file = tempfile.NamedTemporaryFile(delete=False, suffix='.wav')
    temp_path = temp_file.name
    temp_file.close()
    
    # T√©l√©charger le fichier
    response = requests.get(audio_url, stream=True)
    response.raise_for_status()
    
    with open(temp_path, 'wb') as f:
        for chunk in response.iter_content(chunk_size=8192):
            f.write(chunk)
    
    return temp_path


def diarize_audio(audio_path: str) -> dict:
    """
    Effectue la diarisation avec Pyannote
    
    Args:
        audio_path: Chemin du fichier audio
        
    Returns:
        dict: R√©sultat de la diarisation avec segments
    """
    # Application du pipeline
    diarization = pipeline(audio_path)
    
    # Formatage des r√©sultats
    segments = []
    for turn, _, speaker in diarization.itertracks(yield_label=True):
        segments.append({
            "start": float(turn.start),
            "end": float(turn.end),
            "speaker": speaker
        })
    
    return {"segments": segments}


def handler(event):
    """
    Handler principal du worker RunPod
    
    Args:
        event: √âv√©nement contenant les donn√©es de la requ√™te
        
    Returns:
        dict: R√©sultat du traitement
    """
    try:
        input_data = event.get("input", {})
        task = input_data.get("task")
        
        if task != "diarization":
            return {"error": f"T√¢che non support√©e: {task}. Seule 'diarization' est support√©e."}
        
        audio_url = input_data.get("audio_url")
        if not audio_url:
            return {"error": "audio_url est requis"}
        
        # T√©l√©charger l'audio
        print(f"T√©l√©chargement de l'audio depuis: {audio_url}")
        audio_path = download_audio(audio_url)
        
        try:
            # Diarisation
            print("D√©marrage de la diarisation...")
            result = diarize_audio(audio_path)
            print(f"Diarisation termin√©e: {len(result['segments'])} segments trouv√©s")
            
            return result
            
        finally:
            # Nettoyer le fichier temporaire
            if os.path.exists(audio_path):
                os.remove(audio_path)
                
    except Exception as e:
        error_msg = f"Erreur lors du traitement: {str(e)}"
        print(error_msg)
        import traceback
        traceback.print_exc()
        return {"error": error_msg}


# D√©marrage du worker
if __name__ == "__main__":
    runpod.serverless.start({"handler": handler})
```

### 3.2 Cr√©er le fichier requirements.txt

Cr√©ez un fichier `requirements.txt` :

```txt
runpod>=1.0.0
pyannote.audio==4.0.1
torch>=2.2.0
torchaudio>=2.2.0
requests>=2.31.0
```

### 3.3 Cr√©er un Dockerfile (optionnel mais recommand√©)

Cr√©ez un fichier `Dockerfile` :

```dockerfile
FROM runpod/pytorch:2.1.0-py3.10-cuda11.8.0-devel

# Installer les d√©pendances syst√®me
RUN apt-get update && apt-get install -y \
    ffmpeg \
    libsndfile1 \
    && rm -rf /var/lib/apt/lists/*

# Copier les fichiers
WORKDIR /app
COPY requirements.txt .
COPY handler.py .

# Installer les d√©pendances Python
RUN pip install --no-cache-dir -r requirements.txt

# Commande de d√©marrage
CMD ["python", "handler.py"]
```

## üì¶ √âtape 4 : D√©ployer le worker

### Option A : D√©ploiement via GitHub (recommand√©)

**Note importante** : Le Dockerfile est configur√© pour fonctionner depuis la racine du repo. Si vous utilisez votre repo `aodio` existant, c'est parfait !

1. **Dans RunPod, lors de la cr√©ation de l'endpoint** :
   - S√©lectionnez l'option **"Git"**
   - Remplissez :
     - **Repository URL** : `https://github.com/ClementG71/aodio`
     - **Branch** : `main`
     - **Dockerfile Path** : `runpod_worker/Dockerfile.runpod` (dans le dossier runpod_worker/)
     - **Handler Path** : **LAISSER VIDE**
   - RunPod construira automatiquement l'image Docker

2. **Le Dockerfile est d√©j√† configur√©** pour copier les fichiers depuis `runpod_worker/` :
   ```dockerfile
   COPY runpod_worker/requirements.txt ./requirements.txt
   COPY runpod_worker/handler.py ./handler.py
   ```

3. **Si vous pr√©f√©rez cr√©er un repo s√©par√©** (optionnel) :
   - Cr√©ez un nouveau repository GitHub
   - Copiez uniquement le contenu du dossier `runpod_worker/` √† la racine
   - Dans ce cas, utilisez `Dockerfile` (sans le pr√©fixe `runpod_worker/`)

### Option B : D√©ploiement via Docker Hub

1. **Construire l'image Docker localement** :
   ```bash
   cd runpod_worker
   docker build -t votre-nom/pyannote-worker:latest .
   docker push votre-nom/pyannote-worker:latest
   ```

2. **Dans RunPod** :
   - Lors de la cr√©ation, choisissez "Docker"
   - Dans "Docker Image", entrez : `votre-nom/pyannote-worker:latest`
   - Handler path : `/app/handler.py`

### Option C : D√©ploiement via code inline (plus simple mais moins maintenable)

**Note** : Cette option est utile si vous n'avez pas de repository GitHub ou si vous voulez tester rapidement.

1. **Dans RunPod, lors de la cr√©ation de l'endpoint** :
   - Choisissez "Docker"
   - Docker Image : `runpod/pytorch:2.1.0-py3.10-cuda11.8.0-devel`
   - Cr√©ez l'endpoint (vous le configurerez apr√®s)
   
2. **Apr√®s la cr√©ation, modifiez l'endpoint** :
   - Allez dans les param√®tres de votre endpoint (ic√¥ne ‚öôÔ∏è)
   - Section "Handler" :
     - Collez le code complet de `runpod_worker/handler.py` dans le champ "Handler Code"
   - Section "Requirements" :
     - Collez le contenu de `runpod_worker/requirements.txt`
   - Section "Docker Command" :
     - Ajoutez cette commande pour installer les d√©pendances syst√®me et Python :
     ```bash
     apt-get update && apt-get install -y ffmpeg libsndfile1 && pip install --no-cache-dir -r /requirements.txt && python /handler.py
     ```
   - **Important** : Dans cette configuration, le handler doit √™tre √† la racine `/handler.py` et requirements √† `/requirements.txt`

## ‚úÖ √âtape 5 : Tester l'endpoint

### 5.1 R√©cup√©rer l'ID de l'endpoint

Une fois l'endpoint cr√©√©, notez son **Endpoint ID** (visible dans l'URL ou dans les d√©tails de l'endpoint).

### 5.2 Tester avec Python

Cr√©ez un fichier `test_runpod.py` :

```python
import requests
import time

# Configuration
RUNPOD_API_KEY = "votre-api-key-runpod"
ENDPOINT_ID = "votre-endpoint-id"
AUDIO_URL = "https://example.com/test-audio.wav"  # URL d'un fichier audio de test

# Pr√©parer la requ√™te
url = f"https://api.runpod.io/v2/{ENDPOINT_ID}/run"
headers = {
    "Authorization": f"Bearer {RUNPOD_API_KEY}",
    "Content-Type": "application/json"
}

payload = {
    "input": {
        "task": "diarization",
        "audio_url": AUDIO_URL
    }
}

# Envoyer la requ√™te
print("Envoi de la requ√™te...")
response = requests.post(url, headers=headers, json=payload)
response.raise_for_status()

job_data = response.json()
job_id = job_data["id"]
print(f"Job cr√©√©: {job_id}")

# Attendre la compl√©tion
status_url = f"https://api.runpod.io/v2/{ENDPOINT_ID}/status/{job_id}"
max_wait = 600  # 10 minutes

start_time = time.time()
while time.time() - start_time < max_wait:
    status_response = requests.get(status_url, headers=headers)
    status_response.raise_for_status()
    status_data = status_response.json()
    
    status = status_data.get("status")
    print(f"Status: {status}")
    
    if status == "COMPLETED":
        output = status_data.get("output", {})
        segments = output.get("segments", [])
        print(f"\n‚úÖ Succ√®s! {len(segments)} segments trouv√©s:")
        for seg in segments[:5]:  # Afficher les 5 premiers
            print(f"  - {seg['speaker']}: {seg['start']:.2f}s - {seg['end']:.2f}s")
        break
    elif status == "FAILED":
        error = status_data.get("error", "Erreur inconnue")
        print(f"\n‚ùå √âchec: {error}")
        break
    
    time.sleep(5)

if time.time() - start_time >= max_wait:
    print("\n‚è±Ô∏è Timeout: Le job n'a pas termin√© dans le d√©lai imparti")
```

### 5.3 Tester avec cURL

```bash
# Cr√©er le job
curl -X POST "https://api.runpod.io/v2/VOTRE_ENDPOINT_ID/run" \
  -H "Authorization: Bearer VOTRE_API_KEY" \
  -H "Content-Type: application/json" \
  -d '{
    "input": {
      "task": "diarization",
      "audio_url": "https://example.com/test-audio.wav"
    }
  }'

# V√©rifier le status (remplacez JOB_ID)
curl "https://api.runpod.io/v2/VOTRE_ENDPOINT_ID/status/JOB_ID" \
  -H "Authorization: Bearer VOTRE_API_KEY"
```

## üîß √âtape 6 : Configurer les Warm Workers (Workers toujours actifs)

Par d√©faut, RunPod Serverless cr√©e les workers √† la demande. Pour avoir des workers toujours disponibles (recommand√© pour √©viter le cold start) :

### 6.1 Acc√©der aux param√®tres de l'endpoint

1. Allez sur [https://www.runpod.io/console/serverless](https://www.runpod.io/console/serverless)
2. Cliquez sur votre endpoint `aodio`
3. Allez dans l'onglet **"Settings"** (ou cliquez sur le bouton "Manage" ‚Üí "Settings")

### 6.2 Configurer les Warm Workers

1. Dans la section **"Worker Configuration"** ou **"Scaling"** :
   - Trouvez **"Idle Workers"** ou **"Warm Workers"** ou **"Minimum Workers"**
   - D√©finissez le nombre √† **1** (ou plus si vous avez beaucoup de trafic)
   - Cela gardera au moins 1 worker toujours actif

2. **Optionnel - Max Workers** :
   - D√©finissez **"Max Workers"** √† 2-3 pour g√©rer les pics de charge
   - Cela limite les co√ªts tout en permettant la scalabilit√©

3. **Timeout des workers inactifs** :
   - Configurez **"Idle Timeout"** (ex: 5-10 minutes)
   - Les workers inactifs seront arr√™t√©s apr√®s ce d√©lai pour √©conomiser

4. Cliquez sur **"Save"** ou **"Update"**

### 6.3 V√©rifier que les workers d√©marrent

1. Apr√®s avoir sauvegard√©, retournez dans l'onglet **"Workers"**
2. Vous devriez voir un worker en cours de d√©marrage
3. Attendez 1-2 minutes que le worker soit **"Ready"** (statut vert)
4. Le premier d√©marrage peut prendre 2-3 minutes (chargement du mod√®le Pyannote)

### 6.4 Co√ªts des Warm Workers

- **1 worker RTX 3090** : ~$0.29/heure = ~$7/jour si toujours actif
- **Recommandation** : Gardez 1 warm worker pour √©viter le cold start (~2-3 minutes)
- Les workers inactifs co√ªtent moins cher que les workers actifs

## üîß √âtape 7 : Configuration dans l'application Flask

Une fois l'endpoint test√© et fonctionnel, ajoutez les variables d'environnement sur Railway :

```
RUNPOD_API_KEY=votre-api-key-runpod
RUNPOD_ENDPOINT_ID=votre-endpoint-id
```

Vous pouvez trouver votre API key sur [https://www.runpod.io/console/user/settings](https://www.runpod.io/console/user/settings)

## üìä Format des requ√™tes et r√©ponses

### Requ√™te

```json
{
  "input": {
    "task": "diarization",
    "audio_url": "https://example.com/audio.wav"
  }
}
```

### R√©ponse (succ√®s)

```json
{
  "status": "COMPLETED",
  "output": {
    "segments": [
      {
        "start": 0.0,
        "end": 5.2,
        "speaker": "SPEAKER_00"
      },
      {
        "start": 5.2,
        "end": 12.8,
        "speaker": "SPEAKER_01"
      }
    ]
  }
}
```

### R√©ponse (erreur)

```json
{
  "status": "FAILED",
  "error": "Description de l'erreur"
}
```

## üêõ D√©pannage

### Erreur : "Model not found" ou "401 Unauthorized"

- V√©rifiez que le token Hugging Face (`HF_TOKEN`) est correct
- V√©rifiez que vous avez accept√© les conditions d'utilisation sur Hugging Face
- V√©rifiez que le token a les permissions "Read"

### Erreur : "Out of memory" ou "CUDA out of memory"

- Utilisez un GPU avec plus de VRAM (minimum 16 GB recommand√©)
- R√©duisez la taille des fichiers audio (normalisez avant l'envoi)

### Erreur : "Timeout"

- Augmentez le timeout dans la configuration RunPod
- V√©rifiez que l'URL audio est accessible publiquement
- Les fichiers audio longs (>30 min) peuvent prendre du temps

### Le worker ne d√©marre pas

- V√©rifiez les logs dans RunPod (section "Logs")
- V√©rifiez que toutes les d√©pendances sont install√©es
- V√©rifiez que le Dockerfile est correct

## üí∞ Co√ªts estim√©s

- **GPU RTX 3090** : ~$0.29/heure
- **GPU A100** : ~$1.79/heure
- **Temps moyen par r√©union (1h)** : ~2-5 minutes de traitement
- **Co√ªt par r√©union** : ~$0.01-0.15 selon le GPU

## üìù Notes importantes

1. **Cold Start** : Le premier appel peut prendre 1-2 minutes (chargement du mod√®le)
2. **Taille des fichiers** : Les fichiers audio doivent √™tre accessibles via URL publique
3. **Format audio** : WAV, MP3, M4A sont support√©s (Pyannote g√®re la conversion)
4. **Limite de dur√©e** : Pas de limite th√©orique, mais les tr√®s longs fichiers (>2h) peuvent √™tre lents

## üîó Ressources utiles

- [Documentation RunPod](https://docs.runpod.io/)
- [Documentation Pyannote](https://github.com/pyannote/pyannote-audio)
- [Mod√®le Pyannote sur Hugging Face](https://huggingface.co/pyannote/speaker-diarization-3.1)
