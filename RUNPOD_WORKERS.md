# Configuration des Workers RunPod - Guide rapide

## üéØ Probl√®me : "No workers available"

C'est **normal** ! Sur RunPod Serverless, les workers sont cr√©√©s √† la demande par d√©faut.

## ‚úÖ Solution : Configurer des Warm Workers

### Option 1 : Via l'interface web (recommand√©)

1. **Allez sur votre endpoint** :
   - [https://www.runpod.io/console/serverless](https://www.runpod.io/console/serverless)
   - Cliquez sur votre endpoint `aodio`

2. **Onglet "Settings"** :
   - Cliquez sur **"Settings"** ou **"Manage"** ‚Üí **"Settings"**

3. **Section "Worker Configuration"** :
   - Cherchez **"Idle Workers"** ou **"Warm Workers"** ou **"Minimum Workers"**
   - Mettez la valeur √† **1**
   - Cela gardera 1 worker toujours actif

4. **Sauvegardez** :
   - Cliquez sur **"Save"** ou **"Update"**

5. **V√©rifiez** :
   - Retournez dans l'onglet **"Workers"**
   - Vous devriez voir un worker d√©marrer dans 1-2 minutes

### Option 2 : Via l'API RunPod

Si l'interface ne propose pas cette option, vous pouvez utiliser l'API :

```python
import requests

RUNPOD_API_KEY = "votre-api-key"
ENDPOINT_ID = "votre-endpoint-id"

url = f"https://api.runpod.io/v2/{ENDPOINT_ID}/update"
headers = {
    "Authorization": f"Bearer {RUNPOD_API_KEY}",
    "Content-Type": "application/json"
}

# Configurer 1 warm worker
payload = {
    "templateId": "votre-template-id",  # Trouvable dans les d√©tails de l'endpoint
    "gpuIds": "AMPERE_16",  # Type de GPU
    "networkVolumeId": "votre-volume-id",  # Optionnel
    "containerDiskSizeGb": 20,
    "env": [
        {"key": "HF_TOKEN", "value": "votre-token"}
    ],
    "scalingConfig": {
        "minWorkers": 1,  # ‚Üê C'est ici qu'on configure les warm workers
        "maxWorkers": 3
    }
}

response = requests.put(url, headers=headers, json=payload)
print(response.json())
```

## üìä Comportement des Workers

### Sans Warm Workers (par d√©faut)
- ‚ùå **Cold Start** : 2-3 minutes au premier appel (chargement du mod√®le)
- ‚úÖ **Co√ªt** : Pay-per-use uniquement
- ‚ö†Ô∏è **D√©lai** : Chaque requ√™te attend le d√©marrage du worker

### Avec Warm Workers (recommand√©)
- ‚úÖ **Pas de Cold Start** : Worker toujours pr√™t
- ‚úÖ **R√©ponse rapide** : < 30 secondes pour la diarisation
- ‚ö†Ô∏è **Co√ªt** : ~$7/jour pour 1 worker RTX 3090 toujours actif

## üí∞ Optimisation des co√ªts

### Strat√©gie recommand√©e

1. **En d√©veloppement/test** :
   - 0 warm workers (pay-per-use uniquement)
   - Acceptez le cold start pour √©conomiser

2. **En production** :
   - 1 warm worker minimum
   - Max 2-3 workers pour g√©rer les pics
   - Idle timeout : 5-10 minutes

### Calcul des co√ªts

**Avec 1 warm worker RTX 3090** :
- Co√ªt/heure : ~$0.29
- Co√ªt/jour (24h) : ~$7
- Co√ªt/mois : ~$210

**Sans warm worker (pay-per-use)** :
- Co√ªt par r√©union (1h audio, ~5 min traitement) : ~$0.02-0.05
- Si 10 r√©unions/mois : ~$0.20-0.50
- **Beaucoup moins cher** mais avec cold start

## üîç V√©rifier l'√©tat des workers

### Dans l'interface RunPod

1. Onglet **"Workers"** :
   - Vous devriez voir la liste des workers
   - Statut : **"Ready"** (vert) = pr√™t √† traiter
   - Statut : **"Starting"** (orange) = en cours de d√©marrage
   - Statut : **"Idle"** (gris) = inactif mais disponible

### Via l'API

```python
import requests

RUNPOD_API_KEY = "votre-api-key"
ENDPOINT_ID = "votre-endpoint-id"

url = f"https://api.runpod.io/v2/{ENDPOINT_ID}/health"
headers = {"Authorization": f"Bearer {RUNPOD_API_KEY}"}

response = requests.get(url, headers=headers)
print(response.json())
# Devrait retourner le nombre de workers disponibles
```

## üêõ D√©pannage

### Les workers ne d√©marrent pas

1. **V√©rifiez les logs** :
   - Onglet "Logs" de votre endpoint
   - Cherchez les erreurs de build ou de d√©marrage

2. **V√©rifiez la configuration** :
   - Variables d'environnement (HF_TOKEN)
   - GPU Type disponible
   - Cr√©dits RunPod suffisants

3. **V√©rifiez le build** :
   - Onglet "Builds" ‚Üí V√©rifiez que le dernier build a r√©ussi

### Les workers d√©marrent mais crash

1. **V√©rifiez les logs du worker** :
   - Cliquez sur un worker dans l'onglet "Workers"
   - Consultez les logs pour voir l'erreur

2. **Erreur commune** : "HF_TOKEN not found"
   - V√©rifiez que la variable d'environnement est bien configur√©e

### Cold start trop long

- C'est normal : le mod√®le Pyannote prend 1-2 minutes √† charger
- Solution : Configurez 1 warm worker pour √©viter ce d√©lai

## üìù R√©sum√©

1. ‚úÖ Endpoint cr√©√© et build r√©ussi
2. ‚öôÔ∏è Configurer 1 warm worker dans Settings
3. ‚è±Ô∏è Attendre 2-3 minutes que le worker d√©marre
4. ‚úÖ V√©rifier dans l'onglet "Workers" que le statut est "Ready"
5. üöÄ Tester avec une requ√™te de diarisation

Une fois qu'un worker est "Ready", votre endpoint est op√©rationnel !

